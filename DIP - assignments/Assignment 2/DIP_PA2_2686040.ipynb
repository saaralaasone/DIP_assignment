{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division   # Python 2/3 compatibility\n",
    "from skimage import io                            # utilities to read and write images in various formats\n",
    "import numpy as np  # array manipulation package\n",
    "import matplotlib.pylab as plt                    # plotting package\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (7,15)         # set default figure size\n",
    "plt.rcParams['image.cmap'] = 'gray'               # set default colormap to gray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digital Image Processing - Programming Assignment \n",
    "\n",
    "The following progamming assignment involves geometric transformations of images. The deadline for returning your work is **7 April 2022 at 23:59. \n",
    "Please, follow carefully the submission instructions given in the end of this notebook.** You are encouraged to seek information in other places than the course book and lecture material but remember **list all your sources under references**.\n",
    "\n",
    "If you experience problems that you cannot solve using the course material or the Python documentation, or have any questions regarding to the programming assignments, please do not hesitate to contact the course assistant by e-mail at the address dip@unioulu.oulu.fi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**At first, fill in your personal details below.**\n",
    "\n",
    "# Personal details:\n",
    "\n",
    "* **Name(s) and student ID(s): Saara Laasonen, 2686040**\n",
    "* **Contact information: saara.laasonen@student.oulu.fi**`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of curvilinear transformation of an image (parabolic deformation)\n",
    "\n",
    "Study carefully the following code which illustrates step-by-step how to apply a specific curvilinear transformation to an image. Note that the image transformation is performed by the function `warp2d` contained in the file *custom_warp.py*, which is located in the same folder of this notebook. It is thus important to understand the meaning of the arguments required by that function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we load and display the image `cameraman.tif` on the screen. The image size is $256\\times256$ pixels, and usually one assumes a coordinate system where the origin is at the top-corner and the horizontal and vertical coordinates lie within the range $[0,width-1]$ and $[0,height-1]$. However, when dealing with geometric trnasformations, it is often more convenient to define a new coordinate system such that the image lies in the domain $U\\times V = [-1,1]\\times[-1,1]$. This will have the effect of: _a)_ setting the origin of the coordinate system at the center of the image, _b)_ making the geometric transformation independent from the image size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the domain intervals for horizontal and vertical coordinates (they are parameters required by the function `warp2d`):\n",
    "ubound, vbound = [-1,1], [-1,1]\n",
    "\n",
    "# Load and visualize the image:\n",
    "input_image = io.imread(\"cameraman.tif\")\n",
    "plt.imshow(input_image, extent=np.ravel([ubound,vbound]))\n",
    "plt.xlabel('u')\n",
    "plt.ylabel('v')\n",
    "plt.grid(color=[1,1,0.2], alpha=0.3)\n",
    "plt.title(f\"Input image ({input_image.shape[1]}*{input_image.shape[0]} pixels)\" )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now suppose that one wants the above image to be transformed according to the _forward transformation_ $\\tau:U \\times V \\longrightarrow X \\times Y$ defined as follows:\n",
    "\n",
    "$\\tau:\\left\\{\\begin{matrix}\n",
    "x(u,v) & = & u\\\\ \n",
    "y(u,v) & = & v + u^2\n",
    "\\end{matrix}\\right.$\n",
    "\n",
    "The procedure to achieve this is to consider a 2D-array of arbitrary size `output_shape` that will accomodate the pixels of the output image, and for each pixel location $(x,y)$ in it, find its corresponding location in the input image by the _inverse transformation_ $\\tau^{-1}(x,y)$, and finally assign to $(x,y)$ (in the output image) the intensity of the pixel at $\\tau^{-1}(x,y)$ (in the input image). In practice, all this is done internally by `warp2d`, however we must provide the inverse function $\\tau^{-1}$. \n",
    "\n",
    "In this specific example the _inverse function_ $\\tau^{-1}:X \\times Y \\longrightarrow U \\times V$ is easiy obtained by elementary algebra:\n",
    "\n",
    "$\\tau^{-1}:\\left\\{\\begin{matrix}\n",
    "u(x,y) & = & x\\\\ \n",
    "v(x,y) & = & y - x^2\n",
    "\\end{matrix}\\right.$\n",
    "\n",
    "We can now define the inverse transformation $\\tau^{-1}$ in Python code :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The inverse function must take as its argument a numpy array of size Nx2, in which each row represents the [x,y] coordinates\n",
    "# of one of the N points, and it must return an array of the same size containing the transformed [u,v] coordinates\n",
    "# for each point.\n",
    "\n",
    "def inverse_map(xy):\n",
    "    return np.hstack([xy[:,0:1], xy[:,1:2]-xy[:,0:1]**2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we must define suitable values for the size of the output image, and for the bounds of its domain intervals $X$ and $Y$. In principle, all the aforementioned values can be assigned arbitrarily, however the bounds of $X$ and $Y$ are typically chosen in such a way that the whole transformed image is visible, and does not appear cropped. This can be done in several ways. Three possibilities are:\n",
    "\n",
    "_1)_ Manually, by trial and error\n",
    "\n",
    "_2)_ Manually, by using the forward transformation $\\tau$ in order to determine the lower and upper bounds of $x(u,v)$ and $y(u,v)$, when $-1\\leq u,v \\leq 1$\n",
    "\n",
    "_3)_ Automatically, by performing in Pyhton code the calculation in point _2)_.\n",
    "\n",
    "In this example, we choose option _2)_ and we notice that since $x(u,v)=u$ the lower/upper bounds are clearly $[-1,1]$. For $y(u,v)$ it is easy to verify that the lower/upper bounds are reached respectively when $(u,v)=(0,-1)$ and $(u,v)=(1,1)$, and they are $[-1,2]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the bounds for the domain of the output image, as explained above:\n",
    "xbound, ybound = [-1,1], [-1,2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to invoke the warp function `warp2d` to obtain the transformed output image. Note that the function `warp2d` is essentially a wrapper function of [`skimage.transform.warp`](http://scikit-image.org/docs/dev/api/skimage.transform.html#skimage.transform.warp) that accepts domain intervals as its arguments.\n",
    "The syntax for `warp2d` is the following :\n",
    "___\n",
    "*`warp2d`(input_image, inverse_map, ubound=[-1,1], vbound=[-1,1], xbound=[-1,1], ybound=[-1,1], output_shape=None, **kwargs)*\n",
    "\n",
    "__Returns:__ numpy array of size *output_shape* containing the transformed image.\n",
    "\n",
    "__Note:__ The keyword arguments contained in _\\*\\*kwargs_ are the same keyword arguments accepted by [`skimage.transform.warp`](http://scikit-image.org/docs/dev/api/skimage.transform.html#skimage.transform.warp). Please, check the documentation for a complete explanation of the parameters. Some of them are useful to specify, for instance, the _padding_ and the _interpolation_ method to be used.\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the size of the output image:\n",
    "output_shape = [256+128,256]\n",
    "\n",
    "# Invoke the warp function to perform the transformation (see the above instructions for a detailed explanation of the arguments):\n",
    "from custom_warp import warp2d\n",
    "output_image = warp2d(input_image, inverse_map, ubound=ubound, vbound=vbound, xbound=xbound, ybound=ybound, output_shape=output_shape)\n",
    "\n",
    "# Visualize the result:\n",
    "plt.imshow(output_image, extent=np.ravel([xbound,ybound]) )\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.grid(color=[1,1,0.2], alpha=0.3)\n",
    "plt.title(f\"Output image ({output_image.shape[1]}*{output_image.shape[0]} pixels)\" )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Application of Polar-to-Cartesian curvilinear transformation\n",
    "\n",
    "Suppose that a sonar mounted on a ship scans the sea floor by sending acoustic impulses at different angles, and recording the intensity of the returned sound. The directions of the sound impulses are such that the sonar is practically sampling the reflectivity of the sea floor on a polar grid. The samples are then stored into a matrix in which the horizontal axis *u* represents the radial coordinate, and the vertical axis *v* represents the angular coordinate. An example of such an image is found in the file `sonar.png` contained in the folder of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sonar_input = io.imread('sonar.png')\n",
    "\n",
    "plt.imshow(sonar_input)\n",
    "plt.xlabel('u')\n",
    "plt.ylabel('v')\n",
    "plt.title(f\"Input image\" )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above image actually represents an aircraft relic lying on the sea floor, and its appearance looks distorted, especially on the wings. The distortion is caused by the fact that the pixel intensities were originally sampled on a polar grid, but we are now visualizing the image as if its pixels were sampled on a regular Cartesian grid.\n",
    "The main goal will be that of eliminating this distortion by completing the following tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1 Suppose the sonar collected samples on a polar grid at radial coordinates ranging from $0$ to $5$ and angular coordinates ranging from $-60$ to $+60$ degrees. Define two variables containing the respective lower and upper bounds for the coordinates $u$ and $v$ (like _ubound_ and _vbound_ in the previous example), and use them to visualize the image in the new coordinate system (hint: use the _extent_ argument of _imshow_ as in the example in Section 1).**\n",
    "\n",
    "**_Note:_ since numpy trigonometric functions work with radians, it is convenient to express angular coordinates in radians.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ubound, vbound = [0,5], [-1.04719755,1.04719755]\n",
    "input_image = io.imread(\"sonar.png\")\n",
    "plt.imshow(input_image, extent=np.ravel([ubound,vbound]))\n",
    "plt.xlabel('u')\n",
    "plt.ylabel('v')\n",
    "plt.grid(color=[1,1,0.2], alpha=0.3)\n",
    "plt.title(f\"Input image ({input_image.shape[1]}*{input_image.shape[0]} pixels)\" )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the formulas for transforming polar coordinates to Cartesian coordinates are:\n",
    "\n",
    "$\\tau: \\left\\{\\begin{matrix}\n",
    "x(u,v) & = & u\\, \\cos(v)\\\\ \n",
    "y(u,v) & = & u\\, \\sin(v)\n",
    "\\end{matrix}\\right.$\n",
    "\n",
    "Conversely, the Cartesian-to-polar map is given by:\n",
    "\n",
    "$\\tau^{-1}:\\left\\{\\begin{matrix}\n",
    "u(x,y) & = & \\sqrt{x^2+y^2}\\\\ \n",
    "v(x,y) & = & \\mathrm{arctan2}\\left (y,x \\right )\n",
    "\\end{matrix}\\right.$\n",
    "\n",
    "Note that the image _sonar.png_ is defined in the domain $U\\times V$. Hence, following the same reasoning as in the example in the previous Section in this assignment, we seek to obtain an output image defined on a Cartesian domain $X \\times Y$, whose pixel intensities at $(x,y)$ are given by the pixel intensities of `sonar_input` at locations $\\tau^{-1}(x,y)$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.2 Define a Python function that evaluates $\\tau^{-1}$. In other words, you have to define a function that takes a $N\\times 2$ numpy array of coordinates \\[x,y\\] and returns an array of the same size containing the corresponging coordinates \\[u,v\\].**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inverse_map(xy):\n",
    "    return np.hstack([np.sqrt(xy[:,0:1]**2+xy[:,1:2]**2), np.arctan2(xy[:,1:2],xy[:,0:1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.3 Define suitable lower bounds and upper bounds for the $x$ and $y$ coordinates in the output image, and store them respectively in two variables (like _xbound_ and _ybound_ in the previous example). Please, describe very briefly the method you used to obtain the intervals.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am using trial-and-error method. If the photo is not fully in the frame, I make the ybound intervals bigger.\n",
    "xbound, ybound = [0,5], [3*-1.04719755,3*1.04719755]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.4 Choose a suitable size for the output image, and invoke `warp2d` to obtain the transformed output image. Visualize the result by plotting the image. The aircraft should be completely visible and its wings should appear straight. It should be similar to the corrected image attached along this assignment, titled, `sonar_undistorted.png`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the size of the output image:\n",
    "output_shape = [256+128,256]\n",
    "\n",
    "from custom_warp import warp2d\n",
    "output_image = warp2d(input_image, inverse_map, ubound=ubound, vbound=vbound, xbound=xbound, ybound=ybound, output_shape=output_shape)\n",
    "\n",
    "# Visualize the result:\n",
    "plt.imshow(output_image, extent=np.ravel([xbound,ybound]) )\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.grid(color=[1,1,0.2], alpha=0.3)\n",
    "plt.title(f\"Output image ({output_image.shape[1]}*{output_image.shape[0]} pixels)\" )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aftermath\n",
    "Finally, fill your answers to the following questions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How much time did you need to complete this exercise?**\n",
    "\n",
    "`I completed this exercise in 45 minutes.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Did you experience any problems with the exercise? Was there enough help available? Should this notebook be more (or less) detailed?**\n",
    "\n",
    "`I had most trouble with 3.3 but there was enough help in this notebook.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "`Enter your references here`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Submission\n",
    "\n",
    "1. Before submitting your work, **check that your notebook (code) runs from scratch** and reproduces all the requested results by clicking on the menu `Kernel -> Restart & Run All`! Also, check that you have answered all the questions written in **bold**.\n",
    "2. Clear all outputs and variables, etc. by click on the menu `Kernel -> Restart & Clear Output`. This may (or will) reduce the file size of your deliverable a lot! \n",
    "3. Rename this Jupyter notebook to **`DIP_PA2_[student number(s)].ipynb`** (e.g. `DIP_PA2_1234567.ipynb` if solo work or `DIP_PA2_1234567-7654321.ipynb` if pair work) and upload it as your submission to Moodle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
